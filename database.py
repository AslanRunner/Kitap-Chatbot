# -*- coding: utf-8 -*-
# Dosya: database.py
# AmaÃ§: CSV'den kitap verisi yÃ¼kle ve RAG veritabanÄ± oluÅŸtur

import os
import shutil
import pandas as pd
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import google.generativeai as genai
from dotenv import load_dotenv

# =====================================================================
# 1. YAPILANDIRMA
# =====================================================================

CSV_FILE = "kitaplar_temiz.csv"  # Temiz CSV dosyasÄ±
DB_PATH = "./chroma_db"

load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")

if not api_key:
    print("HATA: GEMINI_API_KEY ayarlanmadÄ±!")
    exit()

genai.configure(api_key=api_key)

# =====================================================================
# 2. VERÄ°TABANI OLUÅTURMA
# =====================================================================

def create_database():
    print("ğŸ“š Vector Database OluÅŸturuluyor...\n")
    
    # CSV YÃ¼kle
    print("1ï¸âƒ£ CSV dosyasÄ± yÃ¼kleniyor...")
    if not os.path.exists(CSV_FILE):
        print(f"âŒ Hata: {CSV_FILE} bulunamadÄ±!")
        print(f"   LÃ¼tfen Ã¶nce 'clean_dataset.py' Ã§alÄ±ÅŸtÄ±rÄ±n")
        return
    
    try:
        df = pd.read_csv(CSV_FILE)
        print(f"âœ… {len(df)} kitap yÃ¼klendi.\n")
    except Exception as e:
        print(f"âŒ Hata: {e}")
        return
    
    # Belge OluÅŸtur
    print("2ï¸âƒ£ Belge oluÅŸturuluyor...")
    documents_list = []
    
    for idx, row in df.iterrows():
        if idx % 5000 == 0 and idx > 0:
            print(f"   {idx}/{len(df)} iÅŸlendi...")
        
        book_name = str(row['book_name']).strip()
        author = str(row['author']).strip()
        
        # RAG iÃ§in optimize edilmiÅŸ belge
        doc_text = f"""
KÄ°TAP ADI: {book_name}
YAZAR: {author}

Bu kitap "{book_name}" adlÄ± eser, {author} tarafÄ±ndan yazÄ±lmÄ±ÅŸtÄ±r.
"""
        documents_list.append(doc_text.strip())
    
    print(f"âœ… {len(documents_list)} belge hazÄ±rlandÄ±.\n")
    
    # Metin ParÃ§ala
    print("3ï¸âƒ£ Metinler parÃ§alanÄ±yor...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=300,
        chunk_overlap=50,
        length_function=len,
    )
    documents = text_splitter.create_documents(documents_list)
    print(f"âœ… {len(documents)} chunk oluÅŸturuldu.\n")
    
    # Embedding
    print("4ï¸âƒ£ Embedding modeli yÃ¼kleniyor...")
    embedding_function = GoogleGenerativeAIEmbeddings(
        model="models/text-embedding-004",
        google_api_key=api_key
    )
    print("âœ… Embedding hazÄ±r.\n")
    
    # Eski DB Temizle
    print("5ï¸âƒ£ Eski veritabanÄ± temizleniyor...")
    if os.path.exists(DB_PATH):
        try:
            shutil.rmtree(DB_PATH)
            print(f"âœ… Temizlendi.\n")
        except Exception as e:
            print(f"âš ï¸ Hata: {e}\n")
    
    # DB OluÅŸtur
    print("6ï¸âƒ£ Chroma DB oluÅŸturuluyor...")
    try:
        vectordb = Chroma(
            persist_directory=DB_PATH,
            embedding_function=embedding_function,
            collection_name="turkce-kitap-chatbot",
        )
        
        print("   Belgeler ekleniyor (batch halinde)...")
        batch_size = 5000
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]
            vectordb.add_documents(batch)
            print(f"   {min(i + batch_size, len(documents))}/{len(documents)} eklendi...")
        
        print(f"âœ… DB oluÅŸturuldu.\n")
        
    except Exception as e:
        print(f"âŒ Hata: {e}")
        return
    
    # SonuÃ§
    print("="*70)
    print("âœ… BAÅARILI!")
    print("="*70)
    print(f"ğŸ“Š Toplam kitap: {len(documents_list)}")
    print(f"ğŸ“¦ Toplam chunk: {len(documents)}")
    print(f"ğŸ’¾ VeritabanÄ±: {DB_PATH}")
    print("="*70)

if __name__ == "__main__":
    create_database()
